{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dream \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m dream_symbols\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m# Check each known symbol\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m dream:  \u001b[38;5;66;03m# Direct lookup\u001b[39;00m\n\u001b[1;32m     59\u001b[0m             symbol_counts[symbol] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Convert to a sorted dictionary (most common first)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df = None\n",
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = ''.join([char if char.isalnum() else ' ' for char in text]) \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# what we do is we load the data frame in the same way we did the \n",
    "def get_data():\n",
    "        folder_path = \"./dreams\"\n",
    "        count = 0\n",
    "        all_files = []\n",
    "        for i in os.listdir(folder_path):\n",
    "            if i.endswith('.json'):\n",
    "                count+=1\n",
    "                all_files.append(i)\n",
    "        dreams = []\n",
    "        for i in all_files:\n",
    "            full_name  = os.path.join(folder_path,i)\n",
    "            with open(full_name,'r') as f:\n",
    "                data = json.load(f)\n",
    "                for x in data['dreams']:\n",
    "                    cleaned_content = clean_text(x.get(\"content\", \"\"))\n",
    "                    dreams.append({\n",
    "                        \"content\": cleaned_content\n",
    "                    })\n",
    "                    \n",
    "        return pd.DataFrame(dreams)\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "df_symbols = pd.read_csv(\"dream_dict.csv\")  \n",
    "# Convert to dictionary\n",
    "dream_symbols = {k.lower(): v.lower() for k, v in zip(df_symbols[\"symbol\"], df_symbols[\"interpretation\"])}\n",
    "#print(dream_symbols)\n",
    "symbol_counts = defaultdict(int)\n",
    "\n",
    "# Loop through each dream\n",
    "for dream in df[\"content\"]:\n",
    "    for symbol in dream_symbols.keys():  # Check each known symbol\n",
    "        if symbol in dream:  # Direct lookup\n",
    "            symbol_counts[symbol] += 1\n",
    "\n",
    "# Convert to a sorted dictionary (most common first)\n",
    "symbol_counts = dict(sorted(symbol_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "print(symbol_counts)\n",
    "#print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content\n",
      "571   last night kind stupid dream say makes sense d...\n",
      "756   stephen win 28 000 room stephen ramos playing ...\n",
      "1451  sprained ankle sprained left ankle begins swel...\n",
      "1480  mud lake cabin woods friend kevin simpson two ...\n",
      "1595  flying seaplane take seaplane wind flying plan...\n",
      "1617  light stick game basketball practice long time...\n",
      "1965  sex scully watching episode x files supposed s...\n",
      "2026  crazy soldier german war taking place large bu...\n",
      "2464  close orgasm weight room old teammates simon n...\n",
      "2809  playing quoits woman throwing 2 x 3 square pat...\n"
     ]
    }
   ],
   "source": [
    "# Join all the cleaned dreams into one big text\n",
    "print(df[df[\"content\"].str.contains(\" x \", regex=False)].head(10))\n",
    "text = ' '.join(df['content'].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
